{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed601adb-c970-411a-957c-7990206d6783",
   "metadata": {},
   "source": [
    "### 커스텀 LLM 클래스 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fd5bcc-5906-429c-9d5b-91f79a247263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List, Dict\n",
    "import requests\n",
    "\n",
    "class OllamaLLM(LLM):\n",
    "    api_url: str = \"http://localhost:11434/api/generate\" \n",
    "    model_name: str = \"llama3.2:3B\" \n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": self.model_name,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        response = requests.post(self.api_url, json=payload)\n",
    "        response_data = response.json()\n",
    "        return response_data.get(\"response\", \"No response received.\")\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Dict[str, str]:\n",
    "        return {\"model_name\": self.model_name}\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"ollama\"\n",
    "\n",
    "ollama_llm = OllamaLLM()\n",
    "\n",
    "prompt = \"Why is the sky blue?\"\n",
    "\n",
    "response = ollama_llm.invoke(prompt)\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc84022-4680-4002-93f3-8b70091694d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Instantiation using from_template (recommended)\n",
    "prompt = PromptTemplate.from_template(\"Say {foo}\")\n",
    "prompt.format(foo=\"bar\")\n",
    "\n",
    "# Instantiation using initializer\n",
    "#prompt = PromptTemplate(template=\"Say {foo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec6dfa-13f4-4452-8a68-21cb3e1cf3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f377df24-60ac-4e75-94d0-5745c6348c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template = \"\"\"\n",
    "Hello, my name is {name}. I work as a {profession} with {experience} years of experience. \n",
    "I specialize in {specialization} and have a deep interest in {interests}. \n",
    "Throughout my career, I've been involved in projects like {projects}, which helped me develop strong skills in {skills}.\n",
    "\n",
    "In my free time, I enjoy {hobbies}, as it allows me to relax and recharge. \n",
    "My goal is to {goal}, and I'm constantly looking for opportunities to grow and learn more in this field.\n",
    "People often describe me as {character_traits}, which I believe helps me succeed in my career.\n",
    "\n",
    "Thank you for giving me the opportunity to introduce myself.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4e1198-7ce0-4af4-9a06-327e5f35b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe72583-66f1-4621-8383-ad886be104a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "871d3e30-ca64-4712-b699-eb4723d405e1",
   "metadata": {},
   "source": [
    "### Prompt Template 사용방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2bb123-8c90-4c54-b765-33daa9d27ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_dict = {\n",
    "    \"name\":\"Alice\",\n",
    "    \"profession\":\"Data Scientist\",\n",
    "    \"experience\":\"5\",\n",
    "    \"specialization\":\"machine learning and data analysis\",\n",
    "    \"interests\":\"AI ethics and advanced analytics\",\n",
    "    \"projects\":\"predictive analytics for sales, customer segmentation models\",\n",
    "    \"skills\":\"data modeling, statistical analysis, and machine learning\",\n",
    "    \"hobbies\":\"reading science fiction and hiking\",\n",
    "    \"goal\":\"make impactful contributions in the AI field\",\n",
    "    \"character_traits\":\"curious, detail-oriented, and collaborative\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a456a47d-aa49-4aa9-83a1-dcc47f9d5804",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_dict['hobbies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3f00ab-ac8a-4a01-a9e4-da16ce9c3ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt.format(**profile_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce4dad-59c2-4b4b-8d99-2ffeeb9d5811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0080b3f0-7943-456d-b7b8-6a14f3e34dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 자기소개 프롬프트 템플릿 생성\n",
    "template_text = \"\"\"\n",
    "Hello, my name is {name}. I work as a {profession} with {experience} years of experience. \n",
    "I specialize in {specialization} and have a deep interest in {interests}. \n",
    "Throughout my career, I've been involved in projects like {projects}, which helped me develop strong skills in {skills}.\n",
    "\n",
    "In my free time, I enjoy {hobbies}, as it allows me to relax and recharge. \n",
    "My goal is to {goal}, and I'm constantly looking for opportunities to grow and learn more in this field.\n",
    "People often describe me as {character_traits}, which I believe helps me succeed in my career.\n",
    "\n",
    "Thank you for giving me the opportunity to introduce myself.\n",
    "\"\"\"\n",
    "\n",
    "# 템플릿 생성\n",
    "prompt = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# format 메서드를 사용해 변수 값 채우기\n",
    "result = prompt.format(\n",
    "    aa\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819ee032-dd5b-4915-bb36-57f42871be8e",
   "metadata": {},
   "source": [
    "### Chains 템플릿 사용방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c707c-1072-4271-bea0-aabf02e3bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 첫 번째 프롬프트: 직업을 생성\n",
    "generator_prompt = PromptTemplate.from_template(\n",
    "    \"Randomly create a job name.\"\n",
    ")\n",
    "\n",
    "# 두 번째 프롬프트: 직업을 위한 스킬 목록 생성\n",
    "question_prompt = PromptTemplate.from_template(\n",
    "    \"List the top 5 key skills needed for a {job}.\"\n",
    ")\n",
    "\n",
    "# 세 번째 프롬프트: 간략하게 요약\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"Summarize these key skills for a {job} in one short sentence: {skills}. \"\n",
    "    \"Explain why these skills are critical in a concise way.\"\n",
    ")\n",
    "\n",
    "# 첫 번째 LLM 체인 생성\n",
    "generator_chain = LLMChain(prompt=generator_prompt, llm=ollama_llm, output_key=\"job\")\n",
    "\n",
    "# 두 번째 LLM 체인 생성\n",
    "question_chain = LLMChain(prompt=question_prompt, llm=ollama_llm, output_key=\"skills\")\n",
    "\n",
    "# 세 번째 LLM 체인 생성\n",
    "answer_chain = LLMChain(prompt=answer_prompt, llm=ollama_llm, output_key=\"summary\")\n",
    "\n",
    "# SequentialChain을 이용하여 세 체인 연결\n",
    "chain = SequentialChain(\n",
    "    chains=[generator_chain, question_chain, answer_chain],\n",
    "    input_variables=[],\n",
    "    output_variables=[\"summary\"]\n",
    ")\n",
    "\n",
    "# 체인 실행\n",
    "result = chain.invoke({})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e090be-7849-4206-aef4-8f7c9e0add1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_chain.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644220b-5154-4357-a5c2-c4e7ae58ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_chain.invoke({'job': '\"Interdimensional Experience Coordinator\"'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a246cdf-da64-4a9c-bb3c-b0a63151407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_chain.invoke({'job': '\"Interdimensional Experience Coordinator\"',\n",
    " 'skills': \"What a fascinating role! Here are the top 5 key skills needed for an Interdimensional Experience Coordinator:\\n\\n**1. Multiverse Navigation**: The ability to navigate and understand different dimensions, realities, or planes of existence is crucial for this role. This requires knowledge of interdimensional travel methods, understanding of dimensional energies, and the capacity to adapt to new environments.\\n\\n**2. Interpersonal Communication**: Effective communication with beings from various dimensions, realities, and cultures is essential. The ability to bridge gaps in language, customs, and ideologies will enable the coordinator to facilitate smooth interactions and ensure successful experiences.\\n\\n**3. Experience Design and Facilitation**: As an Interdimensional Experience Coordinator, you'll design and lead immersive experiences that cater to diverse interdimensional travelers. This requires creativity, empathy, and problem-solving skills to tailor experiences that meet the unique needs of each guest.\\n\\n**4. Energy Management and Regulation**: Managing and regulating the flow of energy across dimensions is critical for maintaining stability and preventing unintended consequences. This involves understanding the intricacies of dimensional resonance, vibration frequency, and the impact of energy exchange on both individuals and the fabric of reality.\\n\\n**5. Temporal Awareness and Adaptability**: Interdimensional travel often requires flexibility in regards to temporal aspects. The ability to navigate multiple timelines, account for divergent outcomes, and adapt to changing circumstances will be essential for this role. This involves maintaining a deep understanding of temporal dynamics, being able to analyze and interpret temporal anomalies, and making decisions that minimize disruptions to the fabric of reality.\\n\\nWhile these skills are hypothetical, I hope this gives you an idea of what it might take to excel in this imaginative profession!\"})['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b5da8-931a-46fd-b9b0-67248de465de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3377ccc0-21a8-4671-a2a3-9eb4de1572d9",
   "metadata": {},
   "source": [
    "### agent 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361f185c-543c-4284-a308-5c07e20bff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=\"api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ac3e2-40a7-4e20-9245-022923e585b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "wikipedia = WikipediaAPIWrapper()\n",
    "wikipedia_tool = Tool(name=\"Wikipedia\",\n",
    "                      func=wikipedia.run,\n",
    "                      description=\"\"\n",
    "                     )\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "#get_word_length.invoke(\"abc\")\n",
    "tools = [get_word_length, wikipedia_tool]\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"try to use wikipedia when needed\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "list(agent_executor.stream({\"input\": \"How many letters in the longest word in English?\"}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b07e067-a09f-4e41-b0f1-48686b07136e",
   "metadata": {},
   "source": [
    "### memory 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811fec3-ed2b-454b-8d23-9a721163624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "wikipedia = WikipediaAPIWrapper()\n",
    "wikipedia_tool = Tool(name=\"Wikipedia\",\n",
    "                      func=wikipedia.run,\n",
    "                      description=\"\"\n",
    "                     )\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "#get_word_length.invoke(\"abc\")\n",
    "tools = [get_word_length, wikipedia_tool]\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"try to use wikipedia when needed\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba1f080-3c22-4187-aa01-996f13040414",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = \"How many letters in the longest word in English?\"\n",
    "result = agent_executor.invoke({\"input\": input1, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486bc6f2-15d0-4a69-9b11-bde0115d2320",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=input1),\n",
    "        AIMessage(content=result[\"output\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5948a3a-f592-4d0b-9521-412e5cf11b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cf74f6-d15c-45dd-ac80-e266c6bf0af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input2 = \"What is the second?\"\n",
    "agent_executor.invoke({\"input\": input2, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8994e1c-b581-4976-89a2-d527901d8992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastc",
   "language": "python",
   "name": "fastc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
